<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Teor√≠a 3.3: Detecci√≥n de Anomal√≠as en Profundidad</title>
<style>
    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700;800&family=Roboto:wght@300;400;500;700&display=swap');
    @import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css');

    body { background-color: #f0f2f5; margin: 0; padding: 40px 20px; font-family: 'Roboto', sans-serif; color: #37474f; line-height: 1.8; }

    .container-extended {
        max-width: 1000px; margin: 0 auto; padding: 60px 50px; background: #ffffff;
        border-radius: 20px; box-shadow: 0 10px 40px rgba(0,0,0,0.08); position: relative;
        overflow: hidden; border-top: 8px solid #1565c0;
    }

    .uni-logo { position: absolute; top: 30px; right: 40px; width: 160px; height: auto; z-index: 100; padding: 5px; background: #fff; border-radius: 8px; transition: transform 0.2s ease, box-shadow 0.2s ease; }
    .uni-logo:hover { transform: translateY(-2px) scale(1.02); box-shadow: 0 8px 24px rgba(0,0,0,0.15); }

    .header-box { text-align: left; margin-bottom: 60px; padding-top: 40px; padding-right: 180px; padding-left: 20px; border-bottom: 1px solid #e0e0e0; padding-bottom: 30px; }
    .main-title { font-family: 'Montserrat', sans-serif; font-size: 2.4rem; font-weight: 800; color: #0d47a1; margin: 0 0 15px 0; }

    .content-block { margin-bottom: 50px; font-size: 1.1rem; text-align: justify; }

    /* TARJETAS DE CONCEPTO */
    .concept-grid { display: grid; grid-template-columns: 1fr; gap: 30px; margin-top: 30px; }
    .concept-card {
        background: #f5faff; border: 1px solid #bbdefb; padding: 30px; border-radius: 12px;
        border-left: 6px solid #1565c0;
    }
    .concept-title { color: #0d47a1; font-weight: 700; margin-bottom: 15px; display: block; font-size: 1.3rem; font-family: 'Montserrat', sans-serif; }

    .tradeoff-box {
        background: #fff3e0; border-left: 6px solid #ef6c00; padding: 25px; margin-top: 40px; border-radius: 8px; color: #bf360c; font-size: 1.1rem;
    }

    /* Imagen ilustrativa */
    .feature-img { display:block; max-width:100%; height:auto; border-radius:12px; box-shadow:0 8px 24px rgba(0,0,0,0.08); margin:20px auto; }
    .img-caption { text-align:center; color:#546e7a; font-size:0.9rem; margin-top:8px; }

    @media (max-width: 768px) {
        .uni-logo { position: static; display: block; margin: 0 auto 20px auto; }
        .header-box { padding-right: 20px; text-align: center; }
    }
</style>
</head>
<body>

<div class="container-extended">
    <img src="https://www.dropbox.com/scl/fi/j7mrxq795h9ekhifpcink/logo.png?rlkey=bsh9h5f98pd67n3bfejh368vk&st=8gcmg5vx&raw=1" alt="Logo FET" class="uni-logo">

    <div class="header-box">
        <h1 class="main-title">Casos de Detecci√≥n de Anomal√≠as</h1>
        <p style="color:#546e7a;">Estrategias Supervisadas y No Supervisadas en Seguridad</p>
    </div>

    <div class="content-block">
        <p>Una anomal√≠a, en estad√≠stica, es un dato que se desv√≠a tanto del est√°ndar o de la distribuci√≥n esperada que despierta sospechas de haber sido generado por un mecanismo diferente. En Ciberseguridad, ese "mecanismo diferente" suele ser un actor malicioso, un fallo de sistema o un fraude. Para abordar este problema, el Machine Learning nos ofrece dos grandes paradigmas, cada uno con sus fortalezas y debilidades:</p>

        <figure>
            <img class="feature-img" src="https://www.dropbox.com/scl/fi/47om4xfk2gc5upnf2l3w8/Gemini_Generated_Image_un7p44un7p44un7p.png?rlkey=1g0x4wp54elk8eaxqyu693rbf&st=jpw7dc3b&raw=1" alt="Perrito ilustrando la detecci√≥n de anomal√≠as en ciberseguridad" />
            <figcaption class="img-caption">Semana 6: Detecci√≥n de anomal√≠as ‚Äî sensibilidad vs. falsos positivos.</figcaption>
        </figure>

        <div class="concept-grid">
            <div class="concept-card">
                <span class="concept-title">üëÅÔ∏è Enfoque Supervisado (Clasificaci√≥n)</span>
                <p>En este escenario, contamos con un dataset hist√≥rico que tiene etiquetas claras: cada registro est√° marcado como "Normal" o "Ataque/Fraude".</p>
                <ul>
                    <li><strong>Algoritmos:</strong> Regresi√≥n Log√≠stica, Random Forest, XGBoost, Redes Neuronales.</li>
                    <li><strong>Ventaja:</strong> Alta precisi√≥n para detectar ataques conocidos (firmas aprendidas).</li>
                    <li><strong>Gran Desaf√≠o:</strong> El desbalance de clases. En un mill√≥n de transacciones, quiz√°s solo 10 son fraude. El modelo tiende a ignorar la clase minoritaria si no se usan t√©cnicas de re-muestreo (SMOTE) o m√©tricas adecuadas (Recall). Adem√°s, es ciego a ataques nuevos (Zero-Day) que no estaban en el entrenamiento.</li>
                </ul>
            </div>

            <div class="concept-card">
                <span class="concept-title">üïµÔ∏è Enfoque No Supervisado (Outlier Detection)</span>
                <p>Aqu√≠ no tenemos etiquetas. Asumimos que la gran mayor√≠a de los datos son "normales" y buscamos todo aquello que sea matem√°ticamente diferente o distante.</p>
                <ul>
                    <li><strong>Algoritmos:</strong> Isolation Forest, Local Outlier Factor (LOF), One-Class SVM, Autoencoders.</li>
                    <li><strong>Ventaja:</strong> Capacidad de detectar anomal√≠as desconocidas o ataques nuevos sin necesidad de haberlos visto antes.</li>
                    <li><strong>Gran Desaf√≠o:</strong> La validaci√≥n. Como no hay etiquetas, es dif√≠cil medir qu√© tan bien lo estamos haciendo. Requiere mucha revisi√≥n manual al principio para calibrar qu√© es "raro" vs qu√© es "malo".</li>
                </ul>
            </div>
        </div>

        <div class="tradeoff-box">
            <h3 style="color:#ef6c00; margin-top:0;">‚öñÔ∏è El Dilema del CISO: El Trade-off Operativo</h3>
            <p>Todo sistema de detecci√≥n debe calibrar su sensibilidad. Esto genera una tensi√≥n constante:</p>
            <ul>
                <li><strong>Riesgo de Falsos Positivos (Fatiga de Alertas):</strong> Si el sistema es muy sensible, alertar√° por cualquier desviaci√≥n menor. Esto satura al equipo de seguridad (SOC), quienes empezar√°n a ignorar las alertas, dejando pasar ataques reales.</li>
                <li><strong>Riesgo de Falsos Negativos (Brecha de Seguridad):</strong> Si el sistema es muy estricto para evitar molestar, dejar√° pasar ataques sutiles o lentos ("Low and Slow attacks") que no generan picos estad√≠sticos obvios.</li>
            </ul>
            <p><strong>Soluci√≥n:</strong> No existe una configuraci√≥n perfecta. La soluci√≥n es ajustar el umbral de decisi√≥n din√°micamente y utilizar pol√≠ticas de severidad escalonadas (Info, Warning, Critical).</p>
        </div>

        <h3 style="color:#0d47a1; margin-top:40px;">üîç ¬øC√≥mo validar modelos sin etiquetas?</h3>
        <p>Si usamos un enfoque no supervisado, ¬øc√≥mo sabemos si funciona? Algunas estrategias:</p>
        <ul>
            <li><strong>Muestreo y Revisi√≥n de Expertos:</strong> Toma las 50 anomal√≠as con mayor score y p√°salas a un analista humano. Si 40 son ataques reales o eventos de inter√©s, el modelo es √∫til.</li>
            <li><strong>Inyecci√≥n de Anomal√≠as Sint√©ticas:</strong> Introduce deliberadamente datos an√≥malos en tu dataset de prueba y mide si el modelo es capaz de encontrarlos.</li>
            <li><strong>Reglas Proxy:</strong> Cruza los resultados del modelo con reglas de negocio deterministas (ej. "IP de pa√≠s sancionado", "Login en horario no laboral") para ver si hay correlaci√≥n.</li>
        </ul>
    </div>
</div>

</body>
</html>