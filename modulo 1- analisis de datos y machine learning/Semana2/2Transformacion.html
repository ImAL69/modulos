<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Teoría 1.4: Ingeniería de Características</title>
<style>
    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600;700;800&family=Roboto:wght@300;400;500;700&display=swap');
    @import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css');

    body { background-color: #f0f2f5; margin: 0; padding: 40px 20px; font-family: 'Roboto', sans-serif; color: #37474f; line-height: 1.8; }

    .container-extended {
        max-width: 1000px; margin: 0 auto; padding: 60px 50px; background: #ffffff;
        border-radius: 20px; box-shadow: 0 10px 40px rgba(0,0,0,0.08); position: relative;
        overflow: hidden; border-top: 8px solid #1565c0;
    }

    .uni-logo { position: absolute; top: 30px; right: 40px; width: 160px; height: auto; z-index: 100; padding: 5px; background: #fff; border-radius: 8px; transition: transform 0.2s ease, box-shadow 0.2s ease; }
    .uni-logo:hover { transform: translateY(-2px) scale(1.02); box-shadow: 0 8px 24px rgba(0,0,0,0.15); }

    .header-box { text-align: left; margin-bottom: 60px; padding-top: 40px; padding-right: 180px; padding-left: 20px; border-bottom: 2px solid #e0e0e0; padding-bottom: 30px; }
    .main-title { font-family: 'Montserrat', sans-serif; font-size: 2.4rem; font-weight: 800; color: #0d47a1; margin: 0 0 15px 0; }

    .content-block { margin-bottom: 50px; font-size: 1.1rem; text-align: justify; }

    /* TARJETAS TÉCNICAS DETALLADAS */
    .tech-card {
        background: #f5faff; border: 1px solid #bbdefb; padding: 30px; border-radius: 12px; margin-bottom: 30px;
        border-left: 6px solid #1565c0;
    }
    .tech-title { font-family: 'Montserrat', sans-serif; font-weight: 700; color: #0d47a1; font-size: 1.3rem; margin-bottom: 15px; display: block; }
    
    .code-snippet {
        background-color: #263238; color: #eceff1; padding: 10px; border-radius: 6px; font-family: monospace; display: block; margin-top: 10px;
    }

    /* CAJA DE ALERTA */
    .alert-box {
        background: #fff3e0; border-left: 6px solid #ef6c00; padding: 25px; margin-top: 40px; border-radius: 8px; color: #e65100;
    }

    .qa-box { background: #e3f2fd; border: 1px solid #90caf9; padding: 25px; border-radius: 12px; margin-top: 30px; }
    .qa-q { font-weight: 700; color: #1565c0; display: block; margin-bottom: 10px; font-size: 1.15rem; font-family: 'Montserrat', sans-serif; }
    
    @media (max-width: 768px) {
        .uni-logo { position: static; display: block; margin: 0 auto 20px auto; }
        .header-box { padding-right: 20px; text-align: center; }
    }
</style>
</head>
<body>

<div class="container-extended">
    <img src="https://www.dropbox.com/scl/fi/j7mrxq795h9ekhifpcink/logo.png?rlkey=bsh9h5f98pd67n3bfejh368vk&st=8gcmg5vx&raw=1" alt="Logo FET" class="uni-logo">

    <div class="header-box">
        <h1 class="main-title">Ingeniería de Características (Feature Engineering)</h1>
        <p style="color:#546e7a;">La Ciencia de Transformar Datos en Vectores</p>
    </div>

    <div class="content-block">
        <p>La mayoría de los algoritmos de Machine Learning (Regresión Logística, SVM, Redes Neuronales, K-Means) requieren que todas las variables de entrada sean numéricas y, preferiblemente, estén en la misma escala. La Ingeniería de Características es el arte y la ciencia de adaptar los datos para cumplir con estos requisitos matemáticos sin perder información valiosa.</p>

        <h2 style="color:#0d47a1; margin-top:40px;">1. Transformación de Variables Numéricas (Escalado)</h2>
        <div class="tech-card">
            <span class="tech-title">Estandarización (Z-Score)</span>
            <p>Transforma los datos para que tengan una media de 0 y una desviación estándar de 1. Es crucial para algoritmos que asumen una distribución normal de los errores o que calculan distancias euclidianas (como K-Means, PCA o SVM). Si una variable tiene una varianza mucho mayor que las demás, dominará la función de costo y el modelo no aprenderá correctamente.</p>
            <span class="code-snippet">scaler = StandardScaler() # x_new = (x - mean) / std</span>
        </div>
        <div class="tech-card">
            <span class="tech-title">Normalización (Min-Max Scaling)</span>
            <p>Comprime los datos en un rango fijo, usualmente [0, 1]. Es muy útil para algoritmos que no asumen ninguna distribución específica (como Redes Neuronales) y para procesamiento de imágenes (donde los píxeles van de 0 a 255). Sin embargo, es muy sensible a outliers: un solo valor extremo puede comprimir todos los demás datos en un rango infinitesimal.</p>
            <span class="code-snippet">scaler = MinMaxScaler() # x_new = (x - min) / (max - min)</span>
        </div>

        <h2 style="color:#0d47a1; margin-top:40px;">2. Transformación de Variables Categóricas (Encoding)</h2>
        <div class="tech-card">
            <span class="tech-title">One-Hot Encoding</span>
            <p>Crea una nueva columna binaria (0/1) para cada categoría única. Ideal para variables nominales sin orden (ej. "Protocolo": TCP, UDP, ICMP). Al usar One-Hot, evitamos que el modelo asuma falsamente un orden numérico (ej. que TCP > UDP, lo cual no tiene sentido).</p>
        </div>
        <div class="tech-card">
            <span class="tech-title">Ordinal Encoding</span>
            <p>Asigna un número entero a cada categoría (1, 2, 3...). Solo debe usarse si existe un orden jerárquico real en la variable (ej. "Severidad": Baja=1, Media=2, Alta=3, Crítica=4). Si se usa en variables sin orden, el modelo aprenderá relaciones falsas y su desempeño caerá.</p>
        </div>

        <div class="alert-box">
            <strong>⚠️ Riesgo Crítico: La Maldición de la Dimensionalidad</strong><br>
            Al aplicar One-Hot Encoding a una variable con alta cardinalidad (muchas categorías únicas, como "Dirección IP" o "User Agent"), podrías generar miles o millones de columnas nuevas. Esto hace que el modelo sea computacionalmente costoso y propenso al sobreajuste (necesitarías exponencialmente más datos para entrenarlo). En estos casos, se usan técnicas como "Top-N Encoding" (codificar solo las N más frecuentes y agrupar el resto como 'Otros') o "Target Encoding".
        </div>

        <div class="qa-box">
            <span class="qa-q">Pregunta de Examen: ¿Por qué debemos escalar los datos?</span>
            <div class="qa-a">Si una variable tiene un rango de 0 a 1000 (ej. "Bytes Transmitidos") y otra de 0 a 1 (ej. "Error Flag"), el algoritmo le dará 1000 veces más importancia a la primera variable simplemente por su magnitud numérica, ignorando la segunda. El escalado pone a todas las variables en "igualdad de condiciones" para que el modelo pondere su importancia real basada en la correlación, no en la escala.</div>
        </div>
    </div>
</div>

</body>
</html>